{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tSampling rate, number of samples: 44100 1323000\n",
      "1\tSampling rate, number of samples: 44100 1323000\n",
      "2\tSampling rate, number of samples: 44100 1323000\n",
      "3\tSampling rate, number of samples: 44100 1323000\n",
      "4\tSampling rate, number of samples: 44100 1323000\n",
      "5\tSampling rate, number of samples: 44100 1323000\n",
      "6\tSampling rate, number of samples: 44100 1323000\n",
      "7\tSampling rate, number of samples: 44100 1323000\n",
      "8\tSampling rate, number of samples: 44100 1323000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[array([0.02691697, 0.03661525, 0.03583258, ..., 0.00615601, 0.00683532,\n",
       "       0.01327782]),\n",
       "        0],\n",
       "       [array([0.12133621, 0.0534029 , 0.03995009, ..., 0.00781565, 0.007242  ,\n",
       "       0.00744991]),\n",
       "        0],\n",
       "       [array([0.03315563, 0.03447142, 0.04029038, ..., 0.02939013, 0.02163053,\n",
       "       0.03312321]),\n",
       "        0],\n",
       "       [array([0.05775862, 0.05960753, 0.04840064, ..., 0.02286728, 0.01760071,\n",
       "       0.02309974]),\n",
       "        0],\n",
       "       [array([0.01366833, 0.03232759, 0.04320554, ..., 0.00695013, 0.0052236 ,\n",
       "       0.00620496]),\n",
       "        1],\n",
       "       [array([0.03919011, 0.03822595, 0.04891107, ..., 0.00574882, 0.00415907,\n",
       "       0.00450465]),\n",
       "        1],\n",
       "       [array([0.02959392, 0.02527223, 0.01741152, ..., 0.00757818, 0.00739796,\n",
       "       0.00622492]),\n",
       "        1],\n",
       "       [array([0.04885436, 0.05417423, 0.05723684, ..., 0.00614226, 0.01079344,\n",
       "       0.01535494]),\n",
       "        1],\n",
       "       [array([0.066402  , 0.05336887, 0.05780399, ..., 0.0059058 , 0.00555958,\n",
       "       0.00737059]),\n",
       "        1]], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import audioFeatureExtraction\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess as subp\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "import time\n",
    "\n",
    "def getWavFiles():\n",
    "    files = subp.check_output([\"ls\"]).decode(\"utf8\").split(\"\\n\")\n",
    "    files = [f for f in files if f.split(\".\")[-1] == \"wav\"]\n",
    "    return files\n",
    "\n",
    "# Gets feature vector for a wav song\n",
    "counter = 0\n",
    "def getFeatureVector(file):\n",
    "    global counter\n",
    "\n",
    "    try:\n",
    "        [Fs, x] = audioBasicIO.readAudioFile(file);\n",
    "        x = audioBasicIO.stereo2mono(x)\n",
    "    except:\n",
    "        print(\"Error on file: \", file)\n",
    "        return None\n",
    "\n",
    "    # We cut the audio to a 30 second window in the middle of the song\n",
    "    # If the audio is shorter than 30 second, we discard it\n",
    "    nSamples = Fs * 30\n",
    "    if isinstance(x, int):\n",
    "        return None\n",
    "    elif len(x) < nSamples:\n",
    "        return None\n",
    "    offset   = (len(x) - nSamples) // 2\n",
    "    x = x[offset:offset+nSamples]\n",
    "\n",
    "    print(\"{}\\tSampling rate, number of samples: {} {}\".format(counter, Fs, len(x)))\n",
    "    counter += 1\n",
    "\n",
    "    mterm, sterm, f_names = audioFeatureExtraction.mtFeatureExtraction(x, Fs, 1*Fs, 1*Fs, 0.050*Fs, 0.025*Fs);\n",
    "\n",
    "    # Should return 68 mid-term features per mid-term window (30 windows)\n",
    "    return mterm.ravel()\n",
    "\n",
    "def getDataset():\n",
    "    dataset = []\n",
    "\n",
    "    os.chdir(\"music_negative/\")\n",
    "    files = getWavFiles()\n",
    "    for f in files[:5]:\n",
    "        features = getFeatureVector(f)\n",
    "        if features is not None:\n",
    "            dataset.append([features, 0])\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "    os.chdir(\"music_positive/\")\n",
    "    files = getWavFiles()\n",
    "    for f in files[:5]:\n",
    "        features = getFeatureVector(f)\n",
    "        if features is not None:\n",
    "            dataset.append([features, 1])\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "    return np.array(dataset)\n",
    "\n",
    "def trainModel(trainData, solve=\"lbfgs\", hidden=(10)):\n",
    "    clf = MLPClassifier(solver=solve, alpha=1e-4, hidden_layer_sizes=hidden, random_state=1, max_iter=1000)\n",
    "\n",
    "    X = [ i[0] for i in trainData ]\n",
    "    Y = [ i[1] for i in trainData ]\n",
    "    clf.fit(X, Y)\n",
    "\n",
    "    return clf\n",
    "\n",
    "def experiment(dataset):\n",
    "    # k-fold cross-validation\n",
    "    nFolds = 5\n",
    "    foldSize = len(dataset)//nFolds\n",
    "\n",
    "    for solver in [\"lbfgs\", \"adam\", \"sgd\"]:\n",
    "        print(\"{}\\t{}\\t{}\\t{}\".format(\"layrs\", \"acc\", \"train\", \"test\"))\n",
    "\n",
    "        for layers in [(1), (2), (3), (4), (5), (6), (7), (8), (9), (10), (20), (30), (40), (50), (60), (5,2), (5,4), (10,2), (10,4), (20,2), (20,4)]:\n",
    "            success = 0\n",
    "            attempts = 0\n",
    "\n",
    "            execTries = 10\n",
    "            testTime  = 0\n",
    "            trainTime = 0\n",
    "\n",
    "            for execId in range(execTries):\n",
    "                for i in range(nFolds):\n",
    "                    train_idx = np.array([ True for i in range(len(dataset)) ])\n",
    "                    train_idx[i*foldSize:(i+1)*foldSize] = False\n",
    "\n",
    "                    if i == nFolds-1:\n",
    "                        train_idx[-1] = False\n",
    "\n",
    "                    test_idx = train_idx == False\n",
    "\n",
    "                    train = dataset[train_idx]\n",
    "                    test  = dataset[test_idx]\n",
    "\n",
    "                    # train model\n",
    "                    beg = time.time()\n",
    "                    clf = trainModel(train, solver, layers)\n",
    "                    trainTime += time.time() - beg\n",
    "\n",
    "                    beg = time.time()\n",
    "\n",
    "                    # Calculate accuracy\n",
    "                    for [x,y] in test:\n",
    "                        y_star = clf.predict([x])\n",
    "                        # print(\"[{},{}]\".format(y,y_star))\n",
    "                        if y_star == y:\n",
    "                            success += 1\n",
    "                        attempts += 1\n",
    "\n",
    "                    testTime += time.time() - beg\n",
    "\n",
    "            print(\"{}\\t{}\\t{}\\t{}\\t{}\".format(solver, layers, success / attempts, trainTime / execTries, testTime / execTries))\n",
    "\n",
    "\n",
    "\n",
    "dataset = getDataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([0.02691697, 0.03661525, 0.03583258, ..., 0.00615601, 0.00683532,\n",
      "       0.01327782])\n",
      "  0]\n",
      " [array([0.12133621, 0.0534029 , 0.03995009, ..., 0.00781565, 0.007242  ,\n",
      "       0.00744991])\n",
      "  0]\n",
      " [array([0.03315563, 0.03447142, 0.04029038, ..., 0.02939013, 0.02163053,\n",
      "       0.03312321])\n",
      "  0]\n",
      " [array([0.05775862, 0.05960753, 0.04840064, ..., 0.02286728, 0.01760071,\n",
      "       0.02309974])\n",
      "  0]\n",
      " [array([0.01366833, 0.03232759, 0.04320554, ..., 0.00695013, 0.0052236 ,\n",
      "       0.00620496])\n",
      "  1]\n",
      " [array([0.03919011, 0.03822595, 0.04891107, ..., 0.00574882, 0.00415907,\n",
      "       0.00450465])\n",
      "  1]\n",
      " [array([0.02959392, 0.02527223, 0.01741152, ..., 0.00757818, 0.00739796,\n",
      "       0.00622492])\n",
      "  1]\n",
      " [array([0.04885436, 0.05417423, 0.05723684, ..., 0.00614226, 0.01079344,\n",
      "       0.01535494])\n",
      "  1]\n",
      " [array([0.066402  , 0.05336887, 0.05780399, ..., 0.0059058 , 0.00555958,\n",
      "       0.00737059])\n",
      "  1]]\n",
      "[[-0.72216324 -0.5619213  -0.63816444 ... -0.57865681 -0.48511438\n",
      "   0.03542578]\n",
      " [ 2.43097705  0.90367331 -0.28280681 ... -0.37835105 -0.41387558\n",
      "  -0.60759668]\n",
      " [-0.51382264 -0.74908169 -0.25343841 ...  2.22553411  2.10658182\n",
      "   2.22506399]\n",
      " ...\n",
      " [-0.63276618 -1.55218793 -2.2279738  ... -0.40701179 -0.38655618\n",
      "  -0.74275605]\n",
      " [ 0.01043807  0.97101144  1.20910788 ... -0.58031728  0.20823457\n",
      "   0.26460394]\n",
      " [ 0.59644336  0.90070251  1.25805522 ... -0.60885558 -0.7085866\n",
      "  -0.616348  ]]\n"
     ]
    }
   ],
   "source": [
    "def zNormalize(dataset):\n",
    "    # Each row in the dataset has the feature vector, then its class\n",
    "    feats = dataset[:,0]\n",
    "    \n",
    "    # Transform to matrix\n",
    "    matrix = np.matrix([[col for col in row] for row in feats])\n",
    "    \n",
    "    # For each feature (column), we z-normalize it\n",
    "    for col in range(matrix.shape[1]):\n",
    "        mean = np.mean(matrix[:,col])\n",
    "        std  = np.std(matrix[:,col])\n",
    "        matrix[:,col] = (matrix[:,col] - mean) / std\n",
    "    \n",
    "    # Replace features in the dataset\n",
    "    for row in range(matrix.shape[0]):\n",
    "        dataset[row,0] = np.array(matrix[row,:]).flatten()\n",
    "\n",
    "zNormalize(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.427757009278544e-16, 0.9999999999999999)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [ i[3] for i in dataset[:,0] ]\n",
    "np.mean(data), np.std(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
